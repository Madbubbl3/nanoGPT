{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(file=\"datasets/tinyshakespear.txt\", mode=\"r\", encoding=\"utf-8\") as file:\n",
    "    text = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Citizen:\n",
      "Before we proceed any further, hear me speak.\n",
      "\n",
      "All:\n",
      "Speak, speak.\n",
      "\n",
      "First Citizen:\n",
      "You are all resolved rather to die than to famish?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(text[0:148])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'salut'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chars = sorted(list(set(text)))\n",
    "vocab_size = len(chars)\n",
    "stoi = {c:i for i, c in enumerate(chars)}\n",
    "itos = {i:c for i, c in enumerate(chars)}\n",
    "encode = lambda s:[stoi[c] for c in s]\n",
    "decode = lambda s:\"\".join([itos[i] for i in s])\n",
    "decode(encode(\"salut\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "data = torch.tensor(data = encode(text), dtype=torch.int64)\n",
    "n = int(len(data))//10*9\n",
    "train_data = data[:n]\n",
    "val_data = data[n:]\n",
    "block_size = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context = tensor([18]), target = 47\n",
      "context = tensor([18, 47]), target = 56\n",
      "context = tensor([18, 47, 56]), target = 57\n",
      "context = tensor([18, 47, 56, 57]), target = 58\n",
      "context = tensor([18, 47, 56, 57, 58]), target = 1\n",
      "context = tensor([18, 47, 56, 57, 58,  1]), target = 15\n",
      "context = tensor([18, 47, 56, 57, 58,  1, 15]), target = 47\n",
      "context = tensor([18, 47, 56, 57, 58,  1, 15, 47]), target = 58\n"
     ]
    }
   ],
   "source": [
    "x = train_data[:block_size]\n",
    "y = train_data[1:block_size+1]\n",
    "for i in range(block_size):\n",
    "    xi = x[:i+1]\n",
    "    yi = y[i]\n",
    "    print(f\"context = {xi}, target = {yi}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Helper function (get_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "When input is tensor([39]), target is 49\n",
      "When input is tensor([39, 49]), target is 1\n",
      "When input is tensor([39, 49,  1]), target is 5\n",
      "When input is tensor([39, 49,  1,  5]), target is 43\n",
      "When input is tensor([39, 49,  1,  5, 43]), target is 51\n",
      "When input is tensor([39, 49,  1,  5, 43, 51]), target is 1\n",
      "When input is tensor([39, 49,  1,  5, 43, 51,  1]), target is 44\n",
      "When input is tensor([39, 49,  1,  5, 43, 51,  1, 44]), target is 39\n",
      "When input is tensor([49]), target is 43\n",
      "When input is tensor([49, 43]), target is 50\n",
      "When input is tensor([49, 43, 50]), target is 47\n",
      "When input is tensor([49, 43, 50, 47]), target is 46\n",
      "When input is tensor([49, 43, 50, 47, 46]), target is 53\n",
      "When input is tensor([49, 43, 50, 47, 46, 53]), target is 53\n",
      "When input is tensor([49, 43, 50, 47, 46, 53, 53]), target is 42\n",
      "When input is tensor([49, 43, 50, 47, 46, 53, 53, 42]), target is 1\n",
      "When input is tensor([50]), target is 2\n",
      "When input is tensor([50,  2]), target is 0\n",
      "When input is tensor([50,  2,  0]), target is 21\n",
      "When input is tensor([50,  2,  0, 21]), target is 52\n",
      "When input is tensor([50,  2,  0, 21, 52]), target is 48\n",
      "When input is tensor([50,  2,  0, 21, 52, 48]), target is 59\n",
      "When input is tensor([50,  2,  0, 21, 52, 48, 59]), target is 56\n",
      "When input is tensor([50,  2,  0, 21, 52, 48, 59, 56]), target is 47\n",
      "When input is tensor([43]), target is 52\n",
      "When input is tensor([43, 52]), target is 41\n",
      "When input is tensor([43, 52, 41]), target is 46\n",
      "When input is tensor([43, 52, 41, 46]), target is 47\n",
      "When input is tensor([43, 52, 41, 46, 47]), target is 52\n",
      "When input is tensor([43, 52, 41, 46, 47, 52]), target is 45\n",
      "When input is tensor([43, 52, 41, 46, 47, 52, 45]), target is 1\n",
      "When input is tensor([43, 52, 41, 46, 47, 52, 45,  1]), target is 47\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(1337)\n",
    "block_size = 8\n",
    "batch_size = 4\n",
    "\n",
    "def get_batch(split=\"train\"):\n",
    "    data = train_data if split == \"train\" else val_data\n",
    "    ix = torch.randint(low=0, high=(len(data)-block_size), size=(batch_size,))\n",
    "    x = torch.stack(tensors = [data[i:(i+block_size)] for i in ix])\n",
    "    y = torch.stack(tensors=[data[i+1:i+block_size+1] for i in ix])\n",
    "    # print(data[ix[0]:ix[0]+block_size+1])\n",
    "    return x, y\n",
    "\n",
    "x_ex, y_ex = get_batch(\"train\")\n",
    "\n",
    "for ba in range(batch_size):\n",
    "    for bl in range(block_size):\n",
    "        print(f\"When input is {x_ex[ba, 0:bl+1]}, target is {y_ex[ba, bl]}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Instantiate the ANN"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "B = Batch (N in Pytorch) (here = 4)\n",
    "T = Time (or context or block_size, here = 8)\n",
    "C = Channels / Number of Classes (here: vocab_size = 65)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F\n",
    "torch.manual_seed(1337)\n",
    "\n",
    "class BigramLanguageModel(nn.Module):\n",
    "    \n",
    "\tdef __init__(self, vocab_size: int):\n",
    "\t\tsuper().__init__()\n",
    "\t\t# lookup table: each token looks directly for the next following one\n",
    "\t\tself.token_embedding_table = nn.Embedding(num_embeddings=vocab_size, embedding_dim=vocab_size)\n",
    "\t\n",
    "\tdef forward(self, inputs: torch.Tensor, targets=None):\n",
    "\n",
    "\t\tlogits:torch.Tensor = self.token_embedding_table(inputs) # Tensor of size B, T and C\n",
    "\t\tif targets is None:\n",
    "\t\t\tloss = None\n",
    "\t\telse:\n",
    "\t\t\t# PyTorch API: inputs should be of shape (N,C) = B, C, target should be of shape (N) = B\n",
    "\t\t\tB, T, C = logits.shape\n",
    "\t\t\tlogits = logits.view(B*T, C)\n",
    "\t\t\tyhat = targets.view(B*T)\n",
    "\t\t\tloss = F.cross_entropy(input=logits, target=yhat) \n",
    "\t\t# return the logits and the loss\n",
    "\t\treturn logits, loss\n",
    "\n",
    "\tdef generate(self, idx: torch.Tensor, maxNewTokens:int):\n",
    "\t\t# idx is the (B, T) arrays of indices in the current context\n",
    "\t\tfor _ in range(maxNewTokens):\n",
    "\t\t\t# gets the prediction\n",
    "\t\t\tlogits, loss = self.forward(inputs = idx)\n",
    "\t\t\t# focus on the last one -> dim becomes (B,C)\n",
    "\t\t\tlogits = logits[:,-1,:]\n",
    "\t\t\t# translate to probabilities\n",
    "\t\t\tprobs = F.softmax(input=logits, dim=-1)\n",
    "\t\t\t# sample (1 sample) from the probabilities\n",
    "\t\t\tnew_idx = probs.multinomial(num_samples=1, replacement=True) #(B, 1)\n",
    "\t\t\t# complete the existing string of indices\n",
    "\t\t\tidx = torch.cat(tensors=(idx, new_idx), dim=1) # (B, T+1)\n",
    "\t\treturn idx\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sample from Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nS3fh$-M$gCjxvbRj;pGGju;TgCjXOca!CVtTbV$JSV;xZ$Q!U-Q?3faeDvrVHCDq-mc;ai?Oyvh&ymnk&yhsEXNC&yeAUu'Q?Ifn\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# instance of a bigram model\n",
    "model = BigramLanguageModel(vocab_size=vocab_size)\n",
    "# test forward pass\n",
    "logits, loss = model.forward(x_ex, y_ex)\n",
    "# test generation\n",
    "def sample(\n",
    "\t\tmodel=model, \n",
    "\t   context = torch.zeros(size=(1,1), dtype=torch.int64),\n",
    "\t   maxNewToken = 100):\n",
    "\tidx = torch.zeros(size=(1,1), dtype=torch.int64)\n",
    "\tprediction = model.generate(idx=idx, maxNewTokens=maxNewToken).view(-1)\n",
    "\treturn decode([i.item() for i in prediction])\n",
    "sample()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss = 2.391292095184326\n",
      "\n",
      "CES:\n",
      "Wang tlle y, ibous are!\n",
      "tine;\n",
      "TI'd-ss s tosere mekigofes thindybrerorrengh hes woheryouts, w ch, anthint h satancke an man h, mailaumas t nance sithoullease ars.\n",
      "Fou wit avillat ies I at wenst st ave til m sengd.\n",
      "Me btrd asis quswowischeld t bon.\n",
      "WAr mmit\n",
      "\n",
      "MUMit t hil hriomes he oues t, Yofateg\n"
     ]
    }
   ],
   "source": [
    "# create an optimizer object\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=1e-3)\n",
    "# optimize the model\n",
    "batch_size = 32\n",
    "steps = 30000\n",
    "# steps = 3\n",
    "for _ in range(steps):\n",
    "    # get a new batch sample\n",
    "    xb, yb = get_batch()\n",
    "    # forward pass\n",
    "    logits, loss = model(inputs=xb, targets=yb)\n",
    "    # backward pass\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "print(f\"Loss = {loss.item()}\")\n",
    "print(sample(maxNewToken=300))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mathematical trick for self attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8, 2])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(1337)\n",
    "B, T, C = 4, 8, 2\n",
    "X = torch.randn(size=(B, T, C))\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we want xbow[b, t] = x.mean(b, i<=t)\n",
    "xbow = torch.zeros(size=(B, T, C)) # bow = bag of words\n",
    "for b in range(B):\n",
    "    for t in range(T):\n",
    "        xprev = X[b, :t+1] # dim = (t, C)\n",
    "        xbow[b, t] = xprev.mean(dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wei = torch.tril(torch.ones(size=(T,T))) # dim = (T,T)\n",
    "wei = wei / torch.sum(input=wei, dim=1, keepdim=True)\n",
    "xbow2 = wei @ X # (T,T) @ (B, T, C) -> broadcast: (B, T, T) @ (B, T, C) -> (B, T, C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tril = torch.tril(torch.ones(size=(T,T)))\n",
    "wei = torch.zeros(size=(T,T))\n",
    "wei = wei.masked_fill(mask=tril == 0, value=float(\"-inf\"))\n",
    "wei = wei.softmax(dim=1)\n",
    "xbow3 = wei @ X\n",
    "torch.allclose(input=xbow, other=xbow3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
